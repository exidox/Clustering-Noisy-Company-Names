{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "['apple ', 'apple', 'aapl ', 'apple ', 'apple computers', 'appl ', 'apple ', 'applle', 'aple ', 'microsoft ', 'microsoft ', 'msft ', 'ms ', 'microsoft', 'microsft', 'microsof ', 'microsfot', 'amazoncom ', 'amazon', 'amzn', 'amazon ', 'amazon services', 'amazn', 'amzon', 'amazom ', 'amazom', 'alphabet ', 'alphabet', 'google llc', 'google ', 'google', 'alphabt', 'alphabe ', 'googel', 'goole ', 'facebook ', 'facebook', 'fb ', 'meta platforms', 'meta', 'facebok', 'facbook ', 'metaa', 'mta platforms', 'tesla ', 'tesla motors', 'tesla', 'tsla', 'tesla energy', 'tesl ', 'telsa', 'tesla ', 'tesl', 'berkshire hathaway ', 'berkshire hathaway', 'berkshire ', 'brka', 'brkb', 'berkshire hatway', 'berkshire hthaway ', 'berkshre', 'berkshire hathway', 'alibaba group holding ', 'alibaba', 'alibaba group', 'baba', 'ali baba', 'alibba', 'alibab group', 'alibaba holding', 'alibab', 'johnson  johnson', 'johnson and johnson', 'jj', 'jnj', 'johnson', 'johnsn  johnson', 'johnson  johson', 'j  j', 'johnson johnson', 'jpmorgan chase  co', 'jp morgan chase', 'jpm chase', 'jpmc', 'jp morgan', 'jpmorgan', 'jp morgan', 'jp morganchase', 'jpmogan', 'visa ', 'visa', 'v', 'visa ', 'visa ', 'vsa', 'visa ', 'visa ', 'visaincorporation', 'samsung electronics', 'samsung', 'samsung ', 'samsung ', 'samsung co', 'samsng', 'samusng', 'sammsung', 'samsong', 'nestlé sa', 'nestle', 'nestle ', 'nestle sa', 'nestle ', 'nestl', 'nestl ', 'nestl sa', 'nestlee', 'procter  gamble', 'procter and gamble', 'pg', 'proctor  gamble', 'procter  gambl', 'proctre  gamble', 'p and g', 'pg ', 'procter', 'toyota motor ', 'toyota', 'toyota motors', 'tm', 'toyota ', 'toyta', 'toyot', 'toyota motor ', 'toyta motor', 'walt disney company', 'disney']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sklearn\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_company_names(company_names):\n",
    "    processed_names = []\n",
    "    for name in company_names:\n",
    "        # Remove punctuation\n",
    "        name = re.sub(r'[^\\w\\s]', '', name)\n",
    "        # Convert to lowercase\n",
    "        name = name.lower()\n",
    "        # Expand common abbreviations\n",
    "        name = re.sub(r'\\bltd\\b', 'limited', name)\n",
    "        name = re.sub(r'\\bpvt\\b', 'private', name)\n",
    "        name = re.sub(r'\\bcorp\\b', 'corporation', name)\n",
    "        name = re.sub(r'\\binc\\b', 'incorporation', name)\n",
    "\n",
    "        name = re.sub(r'\\blimited\\b', '', name)\n",
    "        name = re.sub(r'\\bprivate\\b', '', name)\n",
    "        name = re.sub(r'\\bcorporation\\b', '', name)\n",
    "        name = re.sub(r'\\bincorporation\\b', '', name)\n",
    "\n",
    "        # Add more expansions as needed\n",
    "        \n",
    "        processed_names.append(name)\n",
    "    \n",
    "    return processed_names\n",
    "\n",
    "\n",
    "company_names = [\n",
    "    'Apple Inc.', 'Apple', 'AAPL Inc.', 'Apple Corp', 'Apple Computers', 'Appl Inc.', 'Apple Incorporation', 'Applle', 'Aple Inc',\n",
    "    'Microsoft Corporation', 'Microsoft Corp.', 'MSFT Inc.', 'MS Corp', 'Microsoft', 'Microsft', 'Microsof Corporation', 'Microsfot',\n",
    "    'Amazon.com, Inc.', 'Amazon', 'AMZN', 'Amazon Corp', 'Amazon Services', 'Amazn', 'Amzon', 'Amazom Inc', 'Amazom',\n",
    "    'Alphabet Inc.', 'Alphabet', 'Google LLC', 'Google Inc.', 'Google', 'Alphabt', 'Alphabe Inc.', 'Googel', 'Goole Inc',\n",
    "    'Facebook, Inc.', 'Facebook', 'FB Inc.', 'Meta Platforms', 'Meta', 'Facebok', 'Facbook Inc.', 'Metaa', 'Mta Platforms',\n",
    "    'Tesla, Inc.', 'Tesla Motors', 'Tesla', 'TSLA', 'Tesla Energy', 'Tesl Inc', 'Telsa', 'Tesla Incorporation', 'Tesl',\n",
    "    'Berkshire Hathaway Inc.', 'Berkshire Hathaway', 'Berkshire Inc.', 'BRK.A', 'BRK.B', 'Berkshire Hatway', 'Berkshire Hthaway Inc.', 'Berkshre', 'Berkshire Hathway',\n",
    "    'Alibaba Group Holding Limited', 'Alibaba', 'Alibaba Group', 'BABA', 'Ali Baba', 'Alibba', 'Alibab Group', 'AliBaba Holding', 'Alibab',\n",
    "    'Johnson & Johnson', 'Johnson and Johnson', 'J&J', 'JNJ', 'Johnson', 'Johnsn & Johnson', 'Johnson & Johson', 'J & J', 'Johnson Johnson',\n",
    "    'JPMorgan Chase & Co.', 'JP Morgan Chase', 'JPM Chase', 'JPMC', 'J.P. Morgan', 'JPMorgan', 'JP Morgan', 'JP MorganChase', 'JPMogan',\n",
    "    'Visa Inc.', 'Visa', 'V', 'Visa Corporation', 'Visa Corp', 'Vsa', 'Visa Incorporation', 'Visa Inc', 'VisaIncorporation',\n",
    "    'Samsung Electronics', 'Samsung', 'Samsung Corp.', 'Samsung Ltd.', 'Samsung Co.', 'Samsng', 'Samusng', 'Sammsung', 'Samsong',\n",
    "    'Nestlé S.A.', 'Nestle', 'Nestle Inc.', 'Nestle SA', 'Nestle Ltd.', 'Nestl', 'Nestl Inc', 'Nestl S.A', 'Nestlee',\n",
    "    'Procter & Gamble', 'Procter and Gamble', 'P&G', 'Proctor & Gamble', 'Procter & Gambl', 'Proctre & Gamble', 'P and G', 'P&G Inc.', 'Procter',\n",
    "    'Toyota Motor Corporation', 'Toyota', 'Toyota Motors', 'TM', 'Toyota Corp', 'Toyta', 'Toyot', 'Toyota Motor Corp.', 'Toyta Motor',\n",
    "    'Walt Disney Company', 'Disney']\n",
    "print(len(company_names))\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess company names\n",
    "processed_company_names = preprocess_company_names(company_names)\n",
    "\n",
    "print(processed_company_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100.  91.  73. ...  24.  16.  17.]\n",
      " [ 91. 100.  60. ...  12.  17.  18.]\n",
      " [ 73.  60. 100. ...  25.  17.   0.]\n",
      " ...\n",
      " [ 24.  12.  25. ... 100.  20.  12.]\n",
      " [ 24.  25.  25. ...  20. 100.  48.]\n",
      " [ 17.  18.   0. ...  12.  48. 100.]]\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "\n",
    "# Number of companies\n",
    "n = len(company_names)\n",
    "\n",
    "# Initialize the similarity matrix\n",
    "similarity_matrix = np.zeros((n, n))\n",
    "\n",
    "# Compute similarity scores\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if i != j:\n",
    "            similarity_matrix[i, j] = fuzz.ratio(processed_company_names[i], processed_company_names[j])\n",
    "        else:\n",
    "            similarity_matrix[i, j] = 100  # Maximum similarity with itself\n",
    "\n",
    "# Display the similarity matrix\n",
    "print(similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17)\t1.0\n",
      "  (1, 17)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (3, 17)\t1.0\n",
      "  (4, 17)\t0.6198083338665895\n",
      "  (4, 27)\t0.7847532282632054\n",
      "  (5, 16)\t1.0\n",
      "  (6, 17)\t1.0\n",
      "  (7, 18)\t1.0\n",
      "  (8, 15)\t1.0\n",
      "  (9, 62)\t1.0\n",
      "  (10, 62)\t1.0\n",
      "  (11, 68)\t1.0\n",
      "  (12, 67)\t1.0\n",
      "  (13, 62)\t1.0\n",
      "  (14, 60)\t1.0\n",
      "  (15, 61)\t1.0\n",
      "  (16, 59)\t1.0\n",
      "  (17, 11)\t1.0\n",
      "  (18, 10)\t1.0\n",
      "  (19, 12)\t1.0\n",
      "  (20, 10)\t1.0\n",
      "  (21, 10)\t0.655241142049617\n",
      "  (21, 85)\t0.755419781158472\n",
      "  (22, 8)\t1.0\n",
      "  :\t:\n",
      "  (119, 77)\t0.7714888204957104\n",
      "  (120, 76)\t0.6362428780349038\n",
      "  (120, 35)\t0.7714888204957104\n",
      "  (121, 36)\t0.6362428780349038\n",
      "  (121, 78)\t0.7714888204957104\n",
      "  (122, 14)\t1.0\n",
      "  (123, 74)\t1.0\n",
      "  (124, 76)\t1.0\n",
      "  (125, 91)\t0.6732697882708322\n",
      "  (125, 65)\t0.7393969111389017\n",
      "  (126, 91)\t1.0\n",
      "  (127, 66)\t0.7595974874024402\n",
      "  (127, 91)\t0.6503934633219339\n",
      "  (128, 89)\t1.0\n",
      "  (129, 91)\t1.0\n",
      "  (130, 92)\t1.0\n",
      "  (131, 90)\t1.0\n",
      "  (132, 91)\t0.6732697882708322\n",
      "  (132, 65)\t0.7393969111389017\n",
      "  (133, 65)\t0.6850383514650138\n",
      "  (133, 92)\t0.7285070054722167\n",
      "  (134, 97)\t0.5922584684249063\n",
      "  (134, 28)\t0.546314756489305\n",
      "  (134, 26)\t0.5922584684249063\n",
      "  (135, 28)\t1.0\n",
      "Feature Matrix (TF-IDF representation):\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [1.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.59225847]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(processed_company_names)\n",
    "\n",
    "print(X)\n",
    "\n",
    "\n",
    "X_dense = X.toarray()\n",
    "\n",
    "\n",
    "print(\"Feature Matrix (TF-IDF representation):\\n\", X_dense)\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0 -1  0 -1  0  0  0  0  1  1 -1 -1  1  1  1  1 -1  2 -1  2 -1  2  2\n",
      "  3  3  4  4 -1  5  5  4  4 -1  5  6  6 -1  7 -1  6  6 -1  7  8 -1  8 -1\n",
      " -1  8 -1  8 -1  9  9 -1 -1 -1  9  9 -1  9 -1 10 11 -1 10 10 11 -1 10 12\n",
      " 12 -1 -1 -1 12 12 -1 12 -1 13 -1 -1 14 14 14 13 14 15 -1 -1 15 15 -1 15\n",
      " 15 -1 -1 16 16 16 -1 16 16 16 16 17 18 18 17 18 18 18 17 18 19 19 -1 19\n",
      " 19 19 -1 -1 -1 20 21 20 -1 21 21 21 20 20 -1 -1]\n",
      "\n",
      "Clusters:\n",
      "Cluster 0: ['Apple Inc.', 'Apple', 'Apple Corp', 'Appl Inc.', 'Apple Incorporation', 'Applle', 'Aple Inc']\n",
      "Cluster -1: ['AAPL Inc.', 'Apple Computers', 'MSFT Inc.', 'MS Corp', 'Amazon.com, Inc.', 'AMZN', 'Amazon Services', 'Google LLC', 'Googel', 'FB Inc.', 'Meta', 'Metaa', 'Tesla Motors', 'TSLA', 'Tesla Energy', 'Telsa', 'Tesl', 'Berkshire Inc.', 'BRK.A', 'BRK.B', 'Berkshre', 'Alibaba Group Holding Limited', 'BABA', 'AliBaba Holding', 'J&J', 'JNJ', 'Johnson', 'J & J', 'JPMorgan Chase & Co.', 'JPM Chase', 'JPMC', 'Visa', 'V', 'Vsa', 'VisaIncorporation', 'Samsung Electronics', 'Samsung Co.', 'P&G', 'P and G', 'P&G Inc.', 'Procter', 'TM', 'Walt Disney Company', 'Disney']\n",
      "Cluster 1: ['Microsoft Corporation', 'Microsoft Corp.', 'Microsoft', 'Microsft', 'Microsof Corporation', 'Microsfot']\n",
      "Cluster 2: ['Amazon', 'Amazon Corp', 'Amazn', 'Amzon']\n",
      "Cluster 3: ['Amazom Inc', 'Amazom']\n",
      "Cluster 4: ['Alphabet Inc.', 'Alphabet', 'Alphabt', 'Alphabe Inc.']\n",
      "Cluster 5: ['Google Inc.', 'Google', 'Goole Inc']\n",
      "Cluster 6: ['Facebook, Inc.', 'Facebook', 'Facebok', 'Facbook Inc.']\n",
      "Cluster 7: ['Meta Platforms', 'Mta Platforms']\n",
      "Cluster 8: ['Tesla, Inc.', 'Tesla', 'Tesl Inc', 'Tesla Incorporation']\n",
      "Cluster 9: ['Berkshire Hathaway Inc.', 'Berkshire Hathaway', 'Berkshire Hatway', 'Berkshire Hthaway Inc.', 'Berkshire Hathway']\n",
      "Cluster 10: ['Alibaba', 'Ali Baba', 'Alibba', 'Alibab']\n",
      "Cluster 11: ['Alibaba Group', 'Alibab Group']\n",
      "Cluster 12: ['Johnson & Johnson', 'Johnson and Johnson', 'Johnsn & Johnson', 'Johnson & Johson', 'Johnson Johnson']\n",
      "Cluster 13: ['JP Morgan Chase', 'JP MorganChase']\n",
      "Cluster 14: ['J.P. Morgan', 'JPMorgan', 'JP Morgan', 'JPMogan']\n",
      "Cluster 15: ['Visa Inc.', 'Visa Corporation', 'Visa Corp', 'Visa Incorporation', 'Visa Inc']\n",
      "Cluster 16: ['Samsung', 'Samsung Corp.', 'Samsung Ltd.', 'Samsng', 'Samusng', 'Sammsung', 'Samsong']\n",
      "Cluster 17: ['Nestlé S.A.', 'Nestle SA', 'Nestl S.A']\n",
      "Cluster 18: ['Nestle', 'Nestle Inc.', 'Nestle Ltd.', 'Nestl', 'Nestl Inc', 'Nestlee']\n",
      "Cluster 19: ['Procter & Gamble', 'Procter and Gamble', 'Proctor & Gamble', 'Procter & Gambl', 'Proctre & Gamble']\n",
      "Cluster 20: ['Toyota Motor Corporation', 'Toyota Motors', 'Toyota Motor Corp.', 'Toyta Motor']\n",
      "Cluster 21: ['Toyota', 'Toyota Corp', 'Toyta', 'Toyot']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Compute the distance matrix\n",
    "distance_matrix = 100 - similarity_matrix\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "#word_cosine = cosine_distances(distance_matrix)\n",
    "\n",
    "dbscan = DBSCAN(metric='precomputed', eps=10, min_samples=2)\n",
    "labels = dbscan.fit_predict(distance_matrix)\n",
    "\n",
    "print(labels)\n",
    "\n",
    "clusters = {}\n",
    "for idx, label in enumerate(labels):\n",
    "    if label not in clusters:\n",
    "        clusters[label] = []\n",
    "    clusters[label].append(company_names[idx])\n",
    "\n",
    "print(\"\\nClusters:\")\n",
    "for cluster_id, members in clusters.items():\n",
    "    print(f\"Cluster {cluster_id}: {members}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 7\n",
      "Cluster -1: 44\n",
      "Cluster 1: 6\n",
      "Cluster 2: 4\n",
      "Cluster 3: 2\n",
      "Cluster 4: 4\n",
      "Cluster 5: 3\n",
      "Cluster 6: 4\n",
      "Cluster 7: 2\n",
      "Cluster 8: 4\n",
      "Cluster 9: 5\n",
      "Cluster 10: 4\n",
      "Cluster 11: 2\n",
      "Cluster 12: 5\n",
      "Cluster 13: 2\n",
      "Cluster 14: 4\n",
      "Cluster 15: 5\n",
      "Cluster 16: 7\n",
      "Cluster 17: 3\n",
      "Cluster 18: 6\n",
      "Cluster 19: 5\n",
      "Cluster 20: 4\n",
      "Cluster 21: 4\n"
     ]
    }
   ],
   "source": [
    "for cluster_id, members in clusters.items():\n",
    "    print(f\"Cluster {cluster_id}:\" , len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 60 iterations.\n",
      "[ 0  0  0  0 20  0  0  0  0  1  1  1 14  1  1  1  1  2  2  2  2  2  2  2\n",
      "  2  2  3  3  4  4  4  3  3  4  4  5  5  5  6  6  5  5  6 19  7 19  7  7\n",
      "  7  7  7  7  7  9  9  9  8  8  9  9  9  9 20 10 10 10 10 10 10 10 10 12\n",
      " 12 11 11 12 12 12 11 12 13 13 13 18 13 13 13 13 13 14 14 11 14 14 14 14\n",
      " 14 20 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 17 17 18 17\n",
      " 17 17 20 18 17 19 19 19  6 19 19 19 19 19 20 20]\n",
      "\n",
      "Clusters:\n",
      "Cluster 0: ['Apple Inc.', 'Apple', 'AAPL Inc.', 'Apple Corp', 'Appl Inc.', 'Apple Incorporation', 'Applle', 'Aple Inc']\n",
      "Cluster 20: ['Apple Computers', 'Alibaba Group Holding Limited', 'VisaIncorporation', 'P and G', 'Walt Disney Company', 'Disney']\n",
      "Cluster 1: ['Microsoft Corporation', 'Microsoft Corp.', 'MSFT Inc.', 'Microsoft', 'Microsft', 'Microsof Corporation', 'Microsfot']\n",
      "Cluster 14: ['MS Corp', 'Visa Inc.', 'Visa', 'Visa Corporation', 'Visa Corp', 'Vsa', 'Visa Incorporation', 'Visa Inc']\n",
      "Cluster 2: ['Amazon.com, Inc.', 'Amazon', 'AMZN', 'Amazon Corp', 'Amazon Services', 'Amazn', 'Amzon', 'Amazom Inc', 'Amazom']\n",
      "Cluster 3: ['Alphabet Inc.', 'Alphabet', 'Alphabt', 'Alphabe Inc.']\n",
      "Cluster 4: ['Google LLC', 'Google Inc.', 'Google', 'Googel', 'Goole Inc']\n",
      "Cluster 5: ['Facebook, Inc.', 'Facebook', 'FB Inc.', 'Facebok', 'Facbook Inc.']\n",
      "Cluster 6: ['Meta Platforms', 'Meta', 'Metaa', 'TM']\n",
      "Cluster 19: ['Mta Platforms', 'Tesla Motors', 'Toyota Motor Corporation', 'Toyota', 'Toyota Motors', 'Toyota Corp', 'Toyta', 'Toyot', 'Toyota Motor Corp.', 'Toyta Motor']\n",
      "Cluster 7: ['Tesla, Inc.', 'Tesla', 'TSLA', 'Tesla Energy', 'Tesl Inc', 'Telsa', 'Tesla Incorporation', 'Tesl']\n",
      "Cluster 9: ['Berkshire Hathaway Inc.', 'Berkshire Hathaway', 'Berkshire Inc.', 'Berkshire Hatway', 'Berkshire Hthaway Inc.', 'Berkshre', 'Berkshire Hathway']\n",
      "Cluster 8: ['BRK.A', 'BRK.B']\n",
      "Cluster 10: ['Alibaba', 'Alibaba Group', 'BABA', 'Ali Baba', 'Alibba', 'Alibab Group', 'AliBaba Holding', 'Alibab']\n",
      "Cluster 12: ['Johnson & Johnson', 'Johnson and Johnson', 'Johnson', 'Johnsn & Johnson', 'Johnson & Johson', 'Johnson Johnson']\n",
      "Cluster 11: ['J&J', 'JNJ', 'J & J', 'V']\n",
      "Cluster 13: ['JPMorgan Chase & Co.', 'JP Morgan Chase', 'JPM Chase', 'J.P. Morgan', 'JPMorgan', 'JP Morgan', 'JP MorganChase', 'JPMogan']\n",
      "Cluster 18: ['JPMC', 'P&G', 'P&G Inc.']\n",
      "Cluster 15: ['Samsung Electronics', 'Samsung', 'Samsung Corp.', 'Samsung Ltd.', 'Samsung Co.', 'Samsng', 'Samusng', 'Sammsung', 'Samsong']\n",
      "Cluster 16: ['Nestlé S.A.', 'Nestle', 'Nestle Inc.', 'Nestle SA', 'Nestle Ltd.', 'Nestl', 'Nestl Inc', 'Nestl S.A', 'Nestlee']\n",
      "Cluster 17: ['Procter & Gamble', 'Procter and Gamble', 'Proctor & Gamble', 'Procter & Gambl', 'Proctre & Gamble', 'Procter']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "distance_matrix = 100 - similarity_matrix\n",
    "\n",
    "preferences = np.linspace(np.min(similarity_matrix), np.max(similarity_matrix), 10)\n",
    "\n",
    "\n",
    "affinity_propagation = AffinityPropagation(random_state=0, affinity=\"euclidean\", verbose=2, max_iter=500)\n",
    "labels = affinity_propagation.fit_predict(distance_matrix)\n",
    "\n",
    "print(labels)\n",
    "\n",
    "clusters = {}\n",
    "for idx, label in enumerate(labels):\n",
    "    if label not in clusters:\n",
    "        clusters[label] = []\n",
    "    clusters[label].append(company_names[idx])\n",
    "\n",
    "print(\"\\nClusters:\")\n",
    "for cluster_id, members in clusters.items():\n",
    "    print(f\"Cluster {cluster_id}: {members}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 8\n",
      "Cluster 20: 6\n",
      "Cluster 1: 7\n",
      "Cluster 14: 8\n",
      "Cluster 2: 9\n",
      "Cluster 3: 4\n",
      "Cluster 4: 5\n",
      "Cluster 5: 5\n",
      "Cluster 6: 4\n",
      "Cluster 19: 10\n",
      "Cluster 7: 8\n",
      "Cluster 9: 7\n",
      "Cluster 8: 2\n",
      "Cluster 10: 8\n",
      "Cluster 12: 6\n",
      "Cluster 11: 4\n",
      "Cluster 13: 8\n",
      "Cluster 18: 3\n",
      "Cluster 15: 9\n",
      "Cluster 16: 9\n",
      "Cluster 17: 6\n"
     ]
    }
   ],
   "source": [
    "for cluster_id, members in clusters.items():\n",
    "    print(f\"Cluster {cluster_id}:\" , len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
